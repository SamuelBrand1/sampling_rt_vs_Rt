---
title: "Evaluating infection-generating processes for infectious disease situational awareness: Is the renewal process necessary?"
author:
  - name: Samuel P. C. Brand
    orcid: 0000-0003-0645-5367
    affiliations:
      - name: Center for Forecasting and Outbreak Analytics, Centers for Disease Control and Prevention, United States of America
  - name: Sam Abbott
    orcid: 0000-0001-8057-8037
    affiliations:
      - name: Centre for Mathematical Modelling of Infectious Diseases, London School of Hygiene & Tropical Medicine, London, United Kingdom
format:
  pdf:
    toc: false
    number-sections: false
    colorlinks: true
bibliography: references.bib
---

## Abstract

Infectious disease surveillance relies on mathematical and statistical models to generate nowcasts, forecasts, and transmission metrics.
A common assumption is that specific infection-generating processes should be paired with particular surveillance measures, leading to debates about using epidemic growth rates versus effective reproduction numbers for situational awareness.

We develop a flexible framework to systematically evaluate how different infection-generating processes perform across multiple epidemiological outcomes, explicitly examining the decoupling between generative processes and target measures. We test models across simulated scenarios with known outcomes, varying generation interval specifications to assess robustness to misspecification.

[Results to be filled in]

This study provides evidence-based recommendations for model selection in public health surveillance, addressing a critical gap in understanding how different modelling approaches perform across various surveillance tasks.

## Introduction

Infectious disease surveillance is fundamental to public health decision-making, with mathematical models increasingly deployed to generate nowcasts, forecasts, and transmission intensity measures such as the effective reproduction number and epidemic growth rate. The relationship between infection-generating processes and their target measures is often assumed but rarely examined. Recent literature has focused on comparing epidemic growth rates with effective reproduction numbers for situational awareness, conflating two distinct questions: which measure provides better situational awareness, and which process better models the infection-generating mechanism.

In nowcasting and short-term forecasting, this distinction is more widely recognised. Lison et al. [@lison] found that renewal-based generative processes improved nowcasts of effective reproduction numbers, infections, and reported cases. Renewal processes and other mechanistic models are commonly used in forecasting with the assumption that capturing the transmission mechanism improves forecast performance. However, little systematic work has explored this question, and findings from collaborative forecasting hubs remain inconclusive.

We aim to systematically evaluate how infection-generating processes perform across multiple epidemiological outcomes. We develop a generic model framework informed by common practice in situational awareness modelling [@abbott2020epinow2; @abbott2021epinowcast; @scott2021epidemia; @Cori2022], enabling comparison between approaches while maintaining flexibility to capture diverse infection trajectories. Through simulation studies and real-world case studies, we evaluate key infection-generating processes with various latent processes across multiple surveillance tasks. This work contributes to the theoretical understanding of how different generative processes influence model performance and uncertainty quantification for infectious disease dynamics. Our findings provide evidence-based guidance on selecting appropriate model structures for specific public health applications, potentially improving the accuracy of epidemic monitoring, enabling more reliable forecasts for resource allocation, and enhancing overall epidemic response capabilities.

## Methods

In this section, we first introduce the transmission intensity measures used for situational awareness and considered in this study. Second, we describe the components of our generic model framework that we use to construct different model-based approaches to estimating these measures. Third, we describe the experimental matrix of generative models, along with different time points, forecast horizons, and potential misspecification of the underlying generation interval. Fourth, we describe the surveillance task scenarios that we consider, including both simulated epidemics and real-world case studies. Finally, we outline the implementation details and define the evaluation metrics for this implementation.

### Transmission intensity measures for situational awareness

We consider three transmission intensity measures ($T(t)$) that are commonly used targets for real-time surveillance and can be defined from a time series of latent infections ($I(t)$):

- **Logarithmic transformation of latent infections** $T(t) = \ln I(t)$, which directly measures the scale of the epidemic on a logarithmic scale.
- **Time-varying growth rate**, $T(t) = r(t) = \ln (I(t) / I(t-1))$, which quantifies the relative change in infections between consecutive time steps.
- **Time-varying instantaneous reproductive number** $T(t) = \mathcal{R}(t) = I(t) / [I \circ g](t)$, where $x\circ y$ is the discrete convolution of vectors $x$ and $y$, and $g$ represents the generation interval distribution [@abbott2020epinow2; @abbott2021epinowcast; @scott2021epidemia; @Cori2022]. This measures the average number of secondary infections caused by each primary infection.

These measures provide different perspectives on epidemic dynamics and are used for different aspects of situational awareness. The direct transformation between latent infections $I(t)$ and derived measures such as $\mathcal{R}(t)$ raises an important question: which process should be treated as generative and which should be calculated as a transformation of the other? This distinction is central to our analysis.

### Generative model framework for epidemiological data

We use a composable generative model framework, as illustrated in Figure @fig-model-composition, that allows us to systematically experiment with different approaches to estimating the transmission intensity measures. A generative model specifies the full joint probability distribution of all variables in a system, both observed and unobserved, and can be used to simulate complete epidemiological trajectories. Our framework decomposes the generative process into distinct components that can be swapped in and out as modules, enabling us to isolate the effects of specific modelling choices while maintaining a consistent overall structure.

In our framework, each generative model defines one tranmission intensity measure as being *primary* ($T_p(t)$). This primary process is directly modelled through a stochastic process. Other epidemiological processes (which we call *secondary* ($T_s(t)$)) are then calculated as transformations of the primary process and the latent infections generated. This distinction allows us to evaluate how different choices of primary processes affect the estimation of all epidemiological measures of interest. This construction allows us to flexibility reproduce a range of methods for estimating the transmission intensity measures that have been proposed in the literature including the renewal process, growth rate process, and direct infection process [@abbott2020epinow2; @abbott2021epinowcast; @scott2021epidemia; @Cori2022].

![Directed graph representing the generative model components. Shown are model choices we experiment over in this study (green rectangles), the observation model (which is fixed in this study; blue rectangle), and generated quantities (red boxes). The generated quantities are split between a primary transmission intensity measure $T(t)$ which composes with the infection-generating process to generate latent infections, and secondary transmission intensity measures. All transmission intensity measures are targets for surveillance. Each modelled quantity can be constructed conditional on parent quantities on the graph (directed edges).](figures/model_composition.png){#fig-model-composition}

#### Model components

We divide our generative model for epidemiological data into three key components:

1. **The latent process** $Z(t)$ drives the dynamics of the **primary** transmission intensity measure via a transformation $T_p(t) = f(Z(t))$. This component can be used to introduce stochasticity into the system and can take various forms such as random walks or autoregressive processes.
1. **The infection-generating process** specifies how new latent incidence over time $t$, $I(t)$, depends on past incidence $\{I(s),~s < t\}$ and the primary transmission intensity measure $T_p(t)$. From $I(t)$ we can then calculate the secondary transmission intensity measures $T_s(t)$ via a transformation $T_s(t) = g(I(t))$.
3. **The observation model** defines how the trajectory of latent infections $\{I(s),~s \leq t\}$ is transformed into expected epidemiological data counts $Y(t)$ and specifies the probabilistic link between these expected counts and actual observations $y(t)$.

These components compose to define the full generative model, with each component depending on specific choices made for the others, as illustrated in Figure @fig-model-composition.

### Latent process models

The primary transmission intensity measure is defined by a stochastic latent process $Z_t$. We consider three latent process models:

1. **Random walk** with unknown standard deviation $\sigma >0$: 
   $$Z_t = Z_{t-1} + \sigma \epsilon_t.$$

2. **Stable AR(1) process** with unknown parameters $|\psi| < 1$ and $\sigma > 0$:
   $$Z_t = \psi Z_{t-1} + \sigma \epsilon_t.$$

3. **Differenced AR(1) process** with unknown parameters $|\psi| < 1$ and $\sigma > 0$:
   $$\begin{align}
   \Delta Z_t &= \psi \Delta Z_{t-1} + \sigma \epsilon_t,\\
   Z_t &= Z_0 + \sum_{s=1}^t\Delta Z_{s}.
   \end{align}$$

Where $\epsilon_t \sim \text{Normal}(0,1)$ are independent standard normal random variables. These latent processes could potentially be applied to any component of the model framework, though in this study we focus on their application to the infection-generating process. Our choice of latent processes is motivated by those commonly used in the literature [@abbott2020epinow2; @abbott2021epinowcast; @scott2021epidemia; @Cori2022].

### Infection-generating processes

We consider three distinct infection-generating processes, each treating a different transmission intensity measure as primary:

1. **Direct infection process** uses the latent process $Z_t$ to model log-infection incidence directly:   
   $$I_t = \exp(Z_t).$$

2. **Growth rate process** uses the latent process $Z_t$ as the exponential growth rate $r_t = Z_t$ on each time step:
   $$\begin{align}
   I_t &= \exp(r_t) I_{t-1},\qquad t = 2, 3, \dots\\
   I_1 &= \exp(r_1) I_0\qquad \text{Initial condition.}
   \end{align}$$

3. **Renewal process** uses the latent process $Z_t$ as the log-reproductive number $\log R_t = Z_t$:
   $$\begin{align}
   I_t &= R_t \sum_{s \geq 1} I_{t-s} g_s,\qquad t = 2, 3, \dots\\
   I_1 &= R_1 \sum_{s \geq 1} I_{-s} g_s, \qquad \text{Initial condition.}
   \end{align}$$

   The parameters that determine the initial condition of the renewal model are $I_0$ and $R_1$. The initial history of latent infections $I_{-1}, I_{-2},\dots$ is constructed as
   $$I_t = e^{rt} I_0,\qquad t = 0, -1, -2,...$$
   where the exponential growth rate $r$ is determined by the initial reproductive number $R_1$ via the solution to the implicit equation,
   $$R_1 = 1 \Big{/} \sum_{t\geq 1} e^{-rt} g_t.$$


### Observation model

We consider a common situation in epidemic situational awareness where the available data is a time series of counts $y(t)$ for time indices $t = 1, 2, \dots, T$. Typically, $y(t)$ represents incident events such as confirmed cases, hospital admissions, or deaths reported either daily or weekly.

Our observation model consists of a sequential delay process with partial ascertainment at each stage:

1. **Sequential delay mechanism**: We model the observation process as a two-stage delay cascade:
   - First, infections $I(u)$ progress to symptom onset with delay distribution $f_{\theta_1}(d_1)$ and ascertainment fraction $\rho_1$
   - Then, symptom onsets progress to reporting with delay distribution $f_{\theta_2}(d_2)$ and ascertainment fraction $\rho_2$
   
   This gives the conditional expectation:
   $$\mu(t) = \mathbb{E}[y(t) | I] = \rho_2 \sum_{s \leq t} f_{\theta_2}(t-s) \left( \rho_1 \sum_{u \leq s} f_{\theta_1}(s-u) I(u) \right)$$
   
2. **Observation error**: We use a negative binomial distribution to link conditional expectations and actual observations:
   $$y(t) | I \sim \text{NegBin}(\text{mean} = \mu(t), ~ \text{overdispersion} = \alpha).$$

This approach follows common practice in software packages such as EpiNow2 and epidemia, where ascertainment is modeled through a convolution of the latent infection process with a delay distribution [@abbott2020epinow2; @abbott2021epinowcast; @scott2021epidemia].

### Relationship between model formulations and transmission measures

An important aspect of our framework is understanding how different model formulations relate to the transmission intensity measures. Depending on which process is modelled as primary, different measures will either:

1. **Directly emerge** from the model (e.g., $R_t$ naturally emerges from a renewal process model)
2. **Require post-processing calculation** as secondary measures (e.g., calculating $R_t$ from a growth rate model)

This distinction affects how uncertainty propagates through the system. When a measure is directly modelled as the primary process, its uncertainty is explicitly represented in the model. When calculated as a secondary measure, its uncertainty depends on transformations of other uncertain quantities.

For example, in a renewal model, $R_t$ is the primary measure and directly influenced by the latent process, while growth rates must be calculated from the resulting infection trajectory. Conversely, in a growth rate model, $r_t$ is primary while $R_t$ must be calculated post hoc. This framework allows us to systematically evaluate how these modeling choices affect the accuracy and uncertainty of all measures of interest.

### Simulated scenarios

To test our models performance on data with known outcomes we use synthetic scenarios grounded in real-world settings. To do this we use the renewal process model described in the previous section with the Rt trajectory varied between settings. For interpretability we stratify these settings into **Outbreak** and **Endemic** settings. For each of these we then repeat simulation using different generation intervals. See the following sub-sections for more details.

#### Model

We use the renewal process model for all simulations with the following procedure:

1. Take a fixed time series of Rt for 160 days. See the next subsection for more description of these scenarios.
2. Add noise to the fixed Rt estimates draws from a N(0, 0.1) with a fixed seed of `12345`.
3. Simulate daily incidence starting from $I_0 = 10$ cases and a fixed generation interval (GI) probability mass function (PMF) specific to the given scenario.
4. The delay between infection and case ascertainment is represented as a convolution on the true incidence time series **CITATIONS**. For any given infected person the delay between infection and ascertainment is distributed **SOME GAMMA/LOGNORMAL**; this is mapped to our discrete-time forward simulations using double interval censoring of both the time of infection and the time of ascertainment **CITE SWP + OTHERS**.
5. Simulated day of the week periodicity by...
6. Simulate additional negative binomial observation noise on the delayed cases drawn with the mean of the true cases and overdispersion of 10.

#### Time varying reproduction number trajectories

**Outbreak scenarios**

This is the list of scenarios where the initial number of infections is small but $R_t$ is initially significantly greater the 1 (e.g. $R_t > 1.5$).

- *Susceptible depletion*. A smooth transition over time from $R_t > 1$ to $R_t < 1$. This represents a scenario where decrease in $R_t$ is due to greater population immunity, although it should be noted that we aren't modelling that effect mechanistically.
- *Susceptible depletion with measures*. A sharp/discontinuous transition over time from $R_t > 1$ to $R_t < 1$, followed by a sharp transition back to $R_t > 1$ and then smooth transition to $R_t < 1$ again. This represents a scenario where initial decrease in $R_t$ is due to implementation of public health measures to reduce transmission. The sharp transition back to $R_t > 1$ is due to later relaxation of measures.

**Endemic scenarios**

- *Regular variation*. A scenario with an endemic disease with sinusoidal variation in $R_t$ around 1 with some period length $P$: e.g. $R_t = 1 + \xi \sin(2 \pi (t - \phi) / P)$.
- *Regular variation with random effects.* As *Regular* variation scenario but with white noise jitter on $R_t$.

**Other scenarios**

These scenarios were considered but not implemented in this analysis (rather than implemented and then discarded from results).

- *Early outbreak*. Constant $R_t = R_0$ but for a short period.
- *Early outbreak with random effects*. As *Early outbreak* scenario but with white noise jitter on $R_t$.
- *Piecewise constant with large switches*: This scenario provides both sharp changes at the start of the timeseries and more gradual transitions towards the end. $R_t$ varies according to the following schedule:
  - 1.1 for two weeks
  - 2 for two weeks
  - 0.5 for two weeks
  - 1.5 for two weeks
  - 0.75 for two weeks
  - 1.1 for six weeks
  - sine curve centered at 1 with amplitude of 0.3 afterwards

#### Generation intervals scenarios

We use three generation intervals (GIs), corresponding to pathogens with long, medium, and short GIs for each infectious disease scenario. We use discretized, double-censored, and truncation adjusted versions of the GI probability mass functions (PMFs).

1. **Short:** Gamma(shape = 2, scale = 1) truncated at XX which has a mean of XX and a standard deviation of XX when discretised. Approximately corresponds to flu A in Wallinga & Lipsitch, 2006
2. **Medium:** Gamma(shape = 2, scale = 5) truncated at XX which has a mean of XX and a standard deviation of XX when discretised
3. **Long:** Gamma(shape = 2, scale = 10) truncated at XX which has a mean of XX and a standard deviation of XX when discretised

### Inference scenarios

Each simulated scenario was extended by considering three model configurations with different generation interval specifications: correct (matching that used in the simulation), too short (mean reduced to 50% of the simulated value), and too long (mean increased to 200% of the simulated value). This variation in assumed generation time distributions was applied to each model configuration while maintaining the generation time distribution used to simulate the underlying scenario data.

### Model implementation

#### Implementation

We developed each model subcomponent as a submodule within an overarching module framework using Julia 1.11. Development was pre-planned using issues on GitHub and then these were implemented with a pull request-driven workflow to ensure code quality and maintainability with all pull requests being reviewed by at least one reviewer. The modelling framework leverages Julia's type system, implementing models as structs inheriting from a generic model type, with Turing.jl providing the probabilistic programming interface. This approach allowed for the expression of our candidate models using composable components with the minimum of duplicated code. Documentation and testing infrastructure utilize Documenter.jl and Test.jl respectively, ensuring code reliability and accessibility. All submodules were fully tested against synthetic data and theoretical properties. Benchmarking was used to ensure robust performance against a range of auto-differentiable backends. See XX for our code.

#### Validation and prior definitions

We conducted comprehensive prior predictive checks for all models, examining each model component separately and in combination. This included evaluating the latent process, infection-generating mechanism, and observation model independently before assessing the complete model structure. Through iterative refinement of these checks, we developed reasonable yet weakly informative priors that aimed to balance domain knowledge with model stability. This process involved simulating from the prior predictive distribution, assessing the plausibility of generated data against expected epidemiological behaviour, and adjusting prior specifications to ensure numerical stability while aiming to avoid overly restrictive assumptions. The component-wise approach allowed us to identify and address potential issues in specific model elements before they could propagate through the full system. This systematic validation framework helped ensure our priors, reflected our domain knowledge, encoded appropriate uncertainty, and maintained computational feasibility.

This process resulted in analysis-wide priors on the cluster factor of XX. For the latent model priors we specialised by infection generating process aiming for plausible daily growth rates or changes in growth rates depending on if the latent model included differencing. Across all models we set the AR process priors such that the autoregressive dependence was between 0 and 1 with more weight placed oh 0 dependence for differences latent processes. See the SI for a full specification of our prior choices along with prior predictive visualisation.

#### Model fitting

We fit models using the No-U-Turn Sampler (NUTS), via Turing.jl, initialized using multi-pathfinder, via Pathfinder.jl, with all data available up to the estimation date. Based on our subcomponent benchmarking we used reverse auto-differentiation with a compiled tape for all fitting, via ReverseDiff.jl. We repeated fitting weekly for all scenario and model combinations. For each fit, we used 100 initialisations of Pathfinder followed by 1000 warm up samples and 1000 posterior samples from NUTs across 4 parallel chains. We set an adaptation target of 0.95 and maximum tree depth of 12. During development, we monitored model fitting issues when applying individual sub-models to simulated data, iteratively improving model specifications to ensure reliable convergence. We assess sampling quality using rank-normalized R-hat statistics (targeting values below 1.05) while monitoring for numerical instabilities through divergent transitions and maximum tree depth warnings.

We managed model fitting via a Julia module, again using a struct based approach to specify scenarios composably. All fitting was prototyped locally and then run in parallel on JuliaHubs compute platform utilising 32 cores and XX RAM.

### Evaluation

#### Posterior prediction

We fit models to each day and time series being evaluated and visualise posterior predictions of all measures. We assess coverage, the CRPS, and the CRPS of log-transformed data for all observables, scaling all metrics where possible by the performance of the renewal process infection-generating model and stratifying by the target measure. In addition to overall metrics, we report performance by horizon aggregated by week for the following horizons (-4, -2, -1, 0, 1, 2) and over time. Performance is reported both overall and by scenario and case study.

#### Inference efficiency

We report the algorithm settings required to maintain reasonable performance in our simulated scenarios. We also report any diagnostics issues models may have had appropriately stratified to highlight problem areas. As an overall measure of efficiency, we also report the effective sample size per second relative to the renewal process model.

#### Implementation

The evaluation framework uses the scoringutils and scoringRules R packages for quantitative assessment and proper scoring rules, integrated into our Julia workflow using RCall.jl due to a current lack of native Julia alternatives. These packages provide functionality for evaluating probabilistic forecasts, including proper scoring rules like CRPS and logarithmic scores, along with tools for visualization and comparative model assessment. The evaluation infrastructure was developed using the same modular approach and pull request-driven workflow as the core implementation, with all visualization and post-processing tasks implemented in Julia except for the scoring steps.

## Results {#sec-results}

### Validation

Say if it looked okay and reference SI.

### Overall

- Overall summary figure of posterior prediction performance and comment
- Sub panel looking at performance by horizon
- Overall summary figure looking at inference efficiency

### Stratified by scenario

- By scenario summary of posterior prediction performance repeated for all scenarios
- By scenario summary of inference efficiency performance
- Example visualisation by scenario

## Discussion

### Summary

- Our systematic evaluation of infection-generating processes reveals important insights for infectious disease modelling
- <The renewal process model shows [performance level] compared to alternatives across [proportion] of scenarios and target measures>
- <Direct incidence models demonstrate [performance level] for short-term forecasting but [performance level] for transmission intensity estimation>
- <Growth rate models perform [performance level] for growth rate estimation but [performance level] for other measures>
- <Model performance varies by [degree] across epidemiological scenarios, with endemic settings showing [similarity/difference] in optimal approaches compared to outbreak scenarios>
- <Generation interval misspecification impacts all models with [relative impact] on renewal process models>
- <Computational efficiency varies by [degree] across model types, with [model type] offering the best performance-to-cost ratio>
- The choice of infection-generating process should be guided by the specific surveillance task, available computational resources, and confidence in generation interval estimates
- Our findings <support/challenge> the common assumption that mechanistic models necessarily outperform phenomenological approaches for all surveillance tasks


### Strengths and limitations of this work

- No exploration of varying delay distribution impacts
- Stochastic and approximately stochastic inference models not considered
- Latent infection-generating processes not mathematically aligned to study posterior geometry effects
- Limited investigation of generation interval uncertainty beyond misspecification
- Right truncation effects in real-time analysis not examined
- Incomplete scenario coverage in case studies
- Complex prior models (splines, gaussian processes) not investigated
- Full simulation-based calibration not performed
- Focus on real-time situational awareness performance rather than retrospective analysis
- Simulations based on renewal process inference method, representing optimal case scenario

### Strengths and limitations compared to the literature

### Future work

- Investigate alternative infection generation processes for simulations beyond the renewal process model
- Expand analysis to include retrospective performance characteristics
- Study the impact of right truncation in real-time scenarios
- Explore more sophisticated prior modeling approaches
- Implement comprehensive simulation-based calibration
- Examine various delay distribution effects on model performance
- Develop and test stochastic inference frameworks
- Analyze mathematical equivalence of infection-generating processes

### Conclusions

## Funding

## Acknowledgements

## References

## Supplementary Information {.appendix}

### Mathematical Specification of generative models

#### The infection-generating process

The infection incidence processes $(I_t)_{t\geq 1}$ we consider are generated using the general form,

$$I_t = f_I((I_s)_{s < t}, Z_t, \theta),\qquad t \geq 1.$$

Where,

1. $(Z_t)_{t\geq 1}$: A latent stochastic process.
2. $(I_s)_{s < t}$: Incidence strictly before time step $t$.
3. $\theta_I$: Model parameters for the infection generating process including initial conditions $(I_s)_{s<1}$.

Different choices of $f_I$ correspond to different *infection generating processes* (IGPs). In this study, we consider three IGPs:

- *Direct infection*. This IGP uses the latent process $Z_t$ models as a log-infection incidence process:   
  $$I_t = \exp(Z_t).$$
- *Growth rate process.* This IGP uses the latent process $Z_t$ as the exponential growth rate $r_t = Z_t$ on each time step:
  $$\begin{align}
  I_t &= \exp(r_t) I_{t-1},\qquad t = 2, 3, \dots\\
  I_1 &= \exp(r_1) I_0\qquad \text{Initial condition.}
  \end{align}$$
- *Renewal process.* This IGP uses the latent process $Z_t$ as the log-reproductive number $\log R_t = Z_t$.
  $$\begin{align}
  I_t &= R_t \sum_{s \geq 1} I_{t-s} g_s,\qquad t = 2, 3, \dots\\
  I_1 &= R_1 \sum_{s \geq 1} I_{-s} g_s, \qquad \text{Initial condition.}
  \end{align}$$

  The parameters that determine the initial condition of the renewal model are $I_0$ and $R_1$. The initial history of latent infections $I_{-1}, I_{-2},\dots$ is constructed as

  $$I_t = e^{rt} I_0,\qquad t = 0, -1, -2,...$$

  Where the exponential growth rate $r$ is determined by the initial reproductive number $R_1$ via the solution to the implicit equation,

  $$R_1 = 1 \Big{/} \sum_{t\geq 1} e^{-rt} g_t.$$

#### The latent process

In the infection-generating processes (IGPs) considered above, 

1. **Random walk** with unknown standard deviation $\sigma >0$, 
   $$Z_t = Z_{t-1} + \sigma \epsilon_t.$$
2. **Stable AR(1) process** with unknown parameters $|\psi| < 1$ and $\sigma > 0$,
   $$Z_t = \psi Z_{t-1} + \sigma \epsilon_t.$$
3. **Differenced AR(1) process** with unknown parameters $|\psi| < 1$ and $\sigma > 0$,
   $$\begin{align}
   \Delta Z_t &= \psi \Delta Z_{t-1} + \sigma \epsilon_t,\\
   Z_t &= Z_0 + \sum_{s=1}^t\Delta Z_{s}.
   \end{align}$$

In this study, we consider a common situation in epidemic situational awareness that the available data is a time series of counts $y(t)$ for time indices $t = 1, 2, \dots, T$. Typically, $y(t)$ will be a time series of incident events such as determined cases, hospital admissions or deaths reported either daily or weekly. As a generative model for the observed data time series $y(t)$, we invoke an underlying latent infection process $I(t)$ which represents the spread of the underlying infectious pathogen among the target population with each count element of $y(t)$ is assumed to derive, with some ascertainment delay, from a latent infection. We can model ascertainment delay using a parametric distribution function $f_\theta(d),~ d = 0, 1, 2,...$ for the probability of an ascertainment delay of $d$ times steps given distributional parameters $\theta$. Consequently, if this delay distribution does not itself vary over time, the conditional expectation for the data time series is,

$$\mu(t) = \mathbb{E}[y(t) | I] = \sum_{s \leq t} f_\theta(t-s) I(s).$$

In this study, we assume a negative binomial link between conditional expectations and actual observations with mean $\mu(t)$ and overdispersion parameter $\alpha$:

$$y(t) | I \sim \text{NegBin}(\text{mean} = \mu(t), ~ \text{overdispersion} = \alpha).$$ 